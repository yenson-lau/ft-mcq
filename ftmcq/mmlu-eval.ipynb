{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "config: str = \"all\"\n",
    "eval_split: str = \"dev\"\n",
    "model_id: str = \"microsoft/Phi-3-mini-4k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer'],\n",
       "    num_rows: 285\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.',\n",
       " 'subject': 'abstract_algebra',\n",
       " 'choices': ['0', '1', '2', '3'],\n",
       " 'answer': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cais/mmlu\", config, split=eval_split)\n",
    "\n",
    "display(dataset)\n",
    "display(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>How many legs does a banana have?\n",
      "\n",
      "A: 0\n",
      "B: 1\n",
      "C: 2\n",
      "D: 3\n",
      "\n",
      "A<end>\n"
     ]
    }
   ],
   "source": [
    "answer_map = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "example = {\n",
    "    'question': 'How many legs does a banana have?',\n",
    "    'subject': 'example',\n",
    "    'choices': ['0', '1', '2', '3'],\n",
    "    'answer': 0\n",
    "}\n",
    "\n",
    "qa_template = \"\"\"\n",
    "{question}\n",
    "\n",
    "{choices}\n",
    "\n",
    "{answer}\n",
    "\"\"\"[1:-1]\n",
    "\n",
    "def format_question(sample, show_answer: bool = False):\n",
    "    return qa_template.format(\n",
    "        question=sample[\"question\"],\n",
    "        choices=\"\\n\".join(\n",
    "            f\"{answer_map[i]}: {choice}\"\n",
    "            for i, choice in enumerate(sample[\"choices\"])\n",
    "        ),\n",
    "        answer=answer_map[int(sample[\"answer\"])] if show_answer else \"\"\n",
    "    )\n",
    "\n",
    "print(\"<start>\" + format_question(example, show_answer=True) + \"<end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046f8871b2df494cba350b6b7bba2e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer multiple choice questions in the format shown by the example below:\n",
      "\n",
      "Example: How many legs does a banana have?\n",
      "\n",
      "A: 0\n",
      "B: 1\n",
      "C: 2\n",
      "D: 3\n",
      "\n",
      "A\n",
      "\n",
      "Return only the final letter choice. Do not provide any further explanations. No yapping.\n",
      "\n",
      "Question: Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.\n",
      "\n",
      "A: 0\n",
      "B: 1\n",
      "C: 2\n",
      "D: 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "Answer multiple choice questions in the format shown by the example below:\n",
    "\n",
    "Example: {formatted_example}\n",
    "\n",
    "Return only the final letter choice. Do not provide any further explanations. No yapping.\n",
    "\n",
    "Question: {formatted_question}\n",
    "\"\"\"[1:-1].format(\n",
    "    formatted_example=format_question(example, show_answer=True),\n",
    "    formatted_question=\"{formatted_question}\"\n",
    ")\n",
    "\n",
    "print(user_message.format(formatted_question=format_question(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C', 'D', 'D', 'D']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from more_itertools import unzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_prompt(sample) -> str:\n",
    "    formatted_message = user_message.format(formatted_question=format_question(sample))\n",
    "    messages = [{\"role\": \"user\", \"content\": formatted_message}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    assert isinstance(prompt, str)\n",
    "    return prompt\n",
    "\n",
    "def generate_answers_batched(dataset, batch_size=8):\n",
    "    all_predictions = dict[int, str]()\n",
    "    indexed_prompts = sorted(\n",
    "        enumerate(map(generate_prompt, dataset)),\n",
    "        key=lambda i_prompt: len(i_prompt[1])\n",
    "    )\n",
    "\n",
    "    for i in tqdm(range(0, len(indexed_prompts), batch_size), desc=\"Batch\"):\n",
    "        batch_idxs, batch_prompts = unzip(indexed_prompts[i: i + batch_size])\n",
    "        batch_idxs, batch_prompts = list(batch_idxs), list(batch_prompts)\n",
    "\n",
    "        batch_inputs = tokenizer(batch_prompts, padding=True, return_tensors=\"pt\")\n",
    "        batch_input_length = batch_inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_outputs = model.generate(\n",
    "                **batch_inputs.to(model.device),\n",
    "                max_new_tokens=10,\n",
    "                do_sample=True,\n",
    "                temperature=0.001,\n",
    "                top_p=0.999,\n",
    "            )\n",
    "\n",
    "        for j, output in zip(batch_idxs, batch_outputs):\n",
    "            all_predictions[j] = tokenizer.decode(\n",
    "                output[batch_input_length:], skip_special_tokens=True\n",
    "            )\n",
    "\n",
    "    return dataset.add_column(\n",
    "        \"prediction\", [all_predictions[i] for i in range(len(dataset))]\n",
    "    )\n",
    "\n",
    "example_preds = generate_answers_batched(dataset.select(range(4)), batch_size=2)\n",
    "display(example_preds[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 36/36 [00:15<00:00,  2.26it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11269bce03a7429b98ce32ee3806bf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>subject</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>prediction</th>\n",
       "      <th>answer_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find all c in Z_3 such that Z_3[x]/(x^2 + c) i...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statement 1 | If aH is an element of a factor ...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[True, True, False, False, True, False, False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statement 1 | Every element of a group generat...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[True, True, False, False, True, False, False,...</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Statement 1| Every function from a finite set ...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[True, True, False, False, True, False, False,...</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find the characteristic of the ring 2Z.</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[0, 3, 12, 30]</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>What is the sign of the covenant for Jewish m...</td>\n",
       "      <td>world_religions</td>\n",
       "      <td>[The rainbow, Circumcision, A son, Bar mitzvah]</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>What is the Second Gem in Buddhism?</td>\n",
       "      <td>world_religions</td>\n",
       "      <td>[The Dharma, The Sangha, The Buddha, The Bodhi...</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>In which dynasty was the \"Mandate of Heaven\" ...</td>\n",
       "      <td>world_religions</td>\n",
       "      <td>[Shang, Zhou, Han, Xia]</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Which Japanese government promoted a kind of ...</td>\n",
       "      <td>world_religions</td>\n",
       "      <td>[Honen, Tanaka, Tokugawa, Meiji]</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>How can the Upanishads be characterized?</td>\n",
       "      <td>world_religions</td>\n",
       "      <td>[Ritual texts, Philosophical texts, Hymns, Ori...</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question           subject  \\\n",
       "0    Find all c in Z_3 such that Z_3[x]/(x^2 + c) i...  abstract_algebra   \n",
       "1    Statement 1 | If aH is an element of a factor ...  abstract_algebra   \n",
       "2    Statement 1 | Every element of a group generat...  abstract_algebra   \n",
       "3    Statement 1| Every function from a finite set ...  abstract_algebra   \n",
       "4              Find the characteristic of the ring 2Z.  abstract_algebra   \n",
       "..                                                 ...               ...   \n",
       "280   What is the sign of the covenant for Jewish m...   world_religions   \n",
       "281                What is the Second Gem in Buddhism?   world_religions   \n",
       "282   In which dynasty was the \"Mandate of Heaven\" ...   world_religions   \n",
       "283   Which Japanese government promoted a kind of ...   world_religions   \n",
       "284           How can the Upanishads be characterized?   world_religions   \n",
       "\n",
       "                                               choices  answer prediction  \\\n",
       "0                                         [0, 1, 2, 3]       1          C   \n",
       "1    [True, True, False, False, True, False, False,...       1          D   \n",
       "2    [True, True, False, False, True, False, False,...       2          D   \n",
       "3    [True, True, False, False, True, False, False,...       0          D   \n",
       "4                                       [0, 3, 12, 30]       0          A   \n",
       "..                                                 ...     ...        ...   \n",
       "280    [The rainbow, Circumcision, A son, Bar mitzvah]       1          B   \n",
       "281  [The Dharma, The Sangha, The Buddha, The Bodhi...       0          C   \n",
       "282                            [Shang, Zhou, Han, Xia]       1          B   \n",
       "283                   [Honen, Tanaka, Tokugawa, Meiji]       3          D   \n",
       "284  [Ritual texts, Philosophical texts, Hymns, Ori...       1          B   \n",
       "\n",
       "    answer_letter  \n",
       "0               B  \n",
       "1               B  \n",
       "2               C  \n",
       "3               A  \n",
       "4               A  \n",
       "..            ...  \n",
       "280             B  \n",
       "281             A  \n",
       "282             B  \n",
       "283             D  \n",
       "284             B  \n",
       "\n",
       "[285 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = generate_answers_batched(dataset)\n",
    "dataset = dataset.map(lambda d: {\"answer_letter\": answer_map[d[\"answer\"]]})\n",
    "display(dataset.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Accuracy: 0.9964912280701754\n",
      "Answer Accuracy: 0.656140350877193\n"
     ]
    }
   ],
   "source": [
    "fmt_acc = sum(\n",
    "    pred.strip() in answer_map\n",
    "    for pred in dataset[\"prediction\"]\n",
    ") / len(dataset)\n",
    "ans_acc = sum(\n",
    "    pred.strip() == ans.strip()\n",
    "    for pred, ans in zip(dataset[\"prediction\"], dataset[\"answer_letter\"])\n",
    ") / len(dataset)\n",
    "print(f\"Format Accuracy: {fmt_acc}\")\n",
    "print(f\"Answer Accuracy: {ans_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
